{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sci-Kit Learn Pipeline tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline?\n",
    "-a pipeline consists of a chain of processing elements arranged so that the output of each element is the input of the next\n",
    "\n",
    "Sklearn Pipeline ? Sequentially apply a list of transforms and a final estimator. Pipeline of transforms with a final estimator.\n",
    "\n",
    "A typical data science workflow would like\n",
    "\n",
    "    1.Get the training data\n",
    "    2.Clean/preprocess the data\n",
    "    3.Train a machine learning model\n",
    "    4.Evaluate and optimise the model\n",
    "    5.Clean/preprocess new data\n",
    "    6.Fit the model on new data to make predictions.\n",
    "\n",
    "Pipeline in sklearn makes it easy to apply the same preprocessiong  to train, test and furture predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset\n",
    "Boston housing dataset loaded from scikit-learn datasets.\n",
    "\n",
    "$Number of Cases$:The dataset contains a total of 506 cases.\n",
    "\n",
    "$Variables$ :There are 14 attributes in each case of the dataset. \n",
    "They are:\n",
    "\n",
    "CRIM    - per capita crime rate by town\n",
    "\n",
    "ZN      - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "\n",
    "INDUS   - proportion of non-retail business acres per town.\n",
    "\n",
    "CHAS    - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "\n",
    "NOX     - nitric oxides concentration (parts per 10 million)\n",
    "\n",
    "RM      - average number of rooms per dwelling\n",
    "\n",
    "AGE     - proportion of owner-occupied units built prior to 1940\n",
    "\n",
    "DIS     - weighted distances to five Boston employment centres\n",
    "\n",
    "RAD     - index of accessibility to radial highways\n",
    "\n",
    "\n",
    "TAX     - full-value property-tax rate per 10,000\n",
    "\n",
    "PTRATIO - pupil-teacher ratio by town\n",
    "\n",
    "B       - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "\n",
    "LSTAT   - % lower status of the population\n",
    "\n",
    "MEDV    - Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boston housing dataset available in sklearn \n",
    "from sklearn.datasets import load_boston\n",
    "data=load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  \n",
      "0     15.3  396.90   4.98  \n",
      "1     17.8  396.90   9.14  \n",
      "2     17.8  392.83   4.03  \n",
      "3     18.7  394.63   2.94  \n",
      "4     18.7  396.90   5.33  \n",
      "   MEDV\n",
      "0  24.0\n",
      "1  21.6\n",
      "2  34.7\n",
      "3  33.4\n",
      "4  36.2\n"
     ]
    }
   ],
   "source": [
    "#converting to X and y dataframes ..X is features and y is the target variable to be predicted\n",
    "\n",
    "X=pd.DataFrame(data=data.data,columns=data.feature_names)\n",
    "y=pd.DataFrame(data=data.target,columns=['MEDV'])\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "y=np.ravel(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating pipeline\n",
    "\n",
    "$Pipeline (steps= [('nameOfPreprocessor', preprocessor),...,\n",
    "                 ('nameOfMLmodel', MLmodel())])$\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps = [  ('preprocessor', preprocessor)  ,('regressor',RandomForestRegressor()) ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('preprocessor',\n",
      "                 Pipeline(steps=[('imputer', SimpleImputer()),\n",
      "                                 ('scaler', StandardScaler())])),\n",
      "                ('regressor', RandomForestRegressor())])\n"
     ]
    }
   ],
   "source": [
    "rf_model = pipeline.fit(X_train, y_train)\n",
    "print (rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7828458355278474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./rf_model.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(rf_model, './rf_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note\n",
    "\n",
    "In another notebooks we can do rf_model prediction simply by loading the pickle file\n",
    "\n",
    "rf_model = joblib.load('PATH/TO/rf_model.pkl')\n",
    "\n",
    "new_prediction = rf_model.predict(new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
